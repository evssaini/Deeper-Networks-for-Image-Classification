# Deeper-Networks-for-Image-Classification


## üìå Overview

This report details an experimental study on applying and evaluating deep Convolutional Neural Networks (CNNs) for image classification tasks using MNIST and CIFAR-10 datasets. The project focuses on implementing and comparing two CNN architectures: VGG16 and ResNet18. The study involves training these networks under different conditions, including training from scratch, for the simpler MNIST dataset and utilising transfer learning with pre-trained weights for the more complex CIFAR-10 dataset. The report describes the methodologies used for data loading, preprocessing, model building, training and evaluation. Results, supported by training logs, loss curves, and accuracy curves, are presented and evaluated properly. 
A critical analysis of the pros and cons of each architecture based on their performance and training characteristics on the chosen datasets. The report highlights the impact ofthe  design of architectures and transfer learning alongside the advanced training techniques used to achieve high accuracy on image classification.

For more detail understandning, Medium: https://medium.com/@ershveers/deeper-networks-for-image-classification-analysis-on-convolutional-neural-network-cnn-40e6437a5406

## üéØ Objectives

This mini project aims to provide hands-on experience in applying such architectures on datasets mentioned above and evaluating these deep CNNs for image classification.
1.	Implement and train VGG16, ResNet18 for image classification.
2.	Utilise the MNIST dataset and an additional dataset, called CIFAR-10, to evaluate the networks.
3.	Perform and evaluate the classification tasks, including monitoring the training process and quantitatively assessing the results.
4.	Conduct a critical analysis of the models chosen, based on their architectural principles and experimental performance.


## üß† Key Concepts Covered
1. Convolutional Neural Networks (CNNs).
2. Deep network architectures.
3. Backpropagation and optimisation.
4. Overfitting and generalisation.
5. Performance evaluation on image datasets.

## üõ†Ô∏è Technologies Used
1. Python
2. PyTorch
3. NumPy
4. Matplotlib
5. Computer Vision

## üß© Project Workflow
1. Dataset Preparation - Loading and preprocessing image datasets.
2. Model Design - Implementing CNNs with increasing depth.
3. Training - Optimising models using gradient-based methods.
4. Evaluation - Measuring accuracy and loss on validation data.
5. Analysis - Comparing performance across architectures.

## üìà Results & Insights
1. Deeper networks demonstrated improved feature learning capability.
2. Increased depth introduced challenges such as longer training times and the risk of overfitting.
3. Highlighted the importance of architectural balance and regulation.
This project reinforces the trade-offs involved in designing deep learning models for real-world applications.

## üìö Learning Outcomes
1. Hands-on experience with deep CNN architecture.
2. Improved understanding of depth vs performance trade-offs.
3. Practical exposure to PyTorch-based model training pipelines.
4. Strengthened analytical thinking through experimental comparison.

## üîÆ Future Improvements
1. Integration of residual connections (ResNet-style architecture).
2. Hyperparameter optimisation.
3. Evaluation using additional datasets.
4. Performance benchmarking against standard architecture.


